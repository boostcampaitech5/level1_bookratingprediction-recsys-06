{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "107efc7d",
   "metadata": {},
   "source": [
    "막막한 모델 구현을 쉽게 이해하기 위해, baseline의 구조를 하나의 흐름으로 펴는 작업을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a8abf5-a628-4735-90f6-2ac44c300c85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc2999c4",
   "metadata": {},
   "source": [
    "다양한 모델을 위한 args들이 함수의 입력으로 계속 따라붙으면서, baseline의 구조가 복잡하게 느껴진다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b6a698a",
   "metadata": {},
   "source": [
    "우선 FM 모델 하나만의 흐름으로 확인하자.  \n",
    "모델 흐름 이해에는 도움되지 않는 args들을 미리 지정해둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58893eb0-9b05-47a1-b75d-239082af8fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/opt/ml/data/'\n",
    "saved_model_path ='./saved_models'\n",
    "model='FM' # ['FM', 'FFM', 'NCF', 'WDN', 'DCN', 'CNN_FM', 'DeepCoNN']\n",
    "data_shuffle=True\n",
    "test_size=0.2\n",
    "seed=42\n",
    "use_best_model=True\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "loss_fn = 'RMSE'\n",
    "optimizer = 'ADAM'\n",
    "weight_decay = 1e-6\n",
    "\n",
    "device = 'cuda'\n",
    "embed_dim = 16\n",
    "dropout = 0.2\n",
    "mlp_dims = (16,16)\n",
    "num_layers = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fdb0128",
   "metadata": {},
   "source": [
    "미션1 EDA 파일과 실제 데이터가 다른 점이 꽤 존재해서, 이들을 잘 처리해주어야 할 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ba26db-aae4-48b0-b122-d77c496e69f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def context_data_load(args):\n",
    "######################## DATA LOAD\n",
    "users = pd.read_csv(data_path + 'users.csv')\n",
    "books = pd.read_csv(data_path + 'books.csv')\n",
    "train = pd.read_csv(data_path + 'train_ratings.csv')\n",
    "test = pd.read_csv(data_path + 'test_ratings.csv')\n",
    "sub = pd.read_csv(data_path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d40c1c-f67f-4c22-bd1d-f86da74778c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# id와 isbn(책 번호)를 쉬운 index로 바꾼다.\n",
    "ids = pd.concat([train['user_id'], sub['user_id']]).unique()\n",
    "isbns = pd.concat([train['isbn'], sub['isbn']]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c07e116-3446-4b45-bb08-651c18cf84af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2user = {idx:id for idx, id in enumerate(ids)}\n",
    "idx2isbn = {idx:isbn for idx, isbn in enumerate(isbns)}\n",
    "\n",
    "user2idx = {id:idx for idx, id in idx2user.items()}\n",
    "isbn2idx = {isbn:idx for idx, isbn in idx2isbn.items()}\n",
    "\n",
    "# id와 isbn을 간단한 index로 변환\n",
    "train['user_id'] = train['user_id'].map(user2idx)\n",
    "sub['user_id'] = sub['user_id'].map(user2idx)\n",
    "test['user_id'] = test['user_id'].map(user2idx)\n",
    "users['user_id'] = users['user_id'].map(user2idx)\n",
    "\n",
    "train['isbn'] = train['isbn'].map(isbn2idx)\n",
    "sub['isbn'] = sub['isbn'].map(isbn2idx)\n",
    "test['isbn'] = test['isbn'].map(isbn2idx)\n",
    "books['isbn'] = books['isbn'].map(isbn2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76449ae0-eb91-4a07-8037-e9228fe5a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_map(x: int) -> int:\n",
    "    x = int(x)\n",
    "    if x < 20:\n",
    "        return 1\n",
    "    elif x >= 20 and x < 30:\n",
    "        return 2\n",
    "    elif x >= 30 and x < 40:\n",
    "        return 3\n",
    "    elif x >= 40 and x < 50:\n",
    "        return 4\n",
    "    elif x >= 50 and x < 60:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677c9eec-6b39-422f-b7b6-b3f981553dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383494, 3)\n"
     ]
    }
   ],
   "source": [
    "# def process_context_data(users, books, ratings1, ratings2):\n",
    "# location 분리\n",
    "users['location'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "\n",
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0].strip())\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1].strip())\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2].strip())\n",
    "# users = users.drop(['location'], axis=1)\n",
    "\n",
    "users = users.replace(['n/a','na','nan',''], np.nan)\n",
    "\n",
    "ratings = pd.concat([train, test]).reset_index(drop=True)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "081e1998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13426.0</td>\n",
       "      <td>ottawa, ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ottawa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>17.0</td>\n",
       "      <td>seattle, ,</td>\n",
       "      <td>27.0</td>\n",
       "      <td>seattle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3087.0</td>\n",
       "      <td>albuquerque, ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>albuquerque</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>9776.0</td>\n",
       "      <td>humble, ,</td>\n",
       "      <td>38.0</td>\n",
       "      <td>humble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67797</th>\n",
       "      <td>59467.0</td>\n",
       "      <td>lisbon, maine,</td>\n",
       "      <td>36.0</td>\n",
       "      <td>lisbon</td>\n",
       "      <td>maine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67929</th>\n",
       "      <td>59607.0</td>\n",
       "      <td>houston, ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67930</th>\n",
       "      <td>59608.0</td>\n",
       "      <td>sammamish, ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sammamish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68058</th>\n",
       "      <td>59762.0</td>\n",
       "      <td>calgary, ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>calgary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68068</th>\n",
       "      <td>59776.0</td>\n",
       "      <td>bolligen, bern,</td>\n",
       "      <td>24.0</td>\n",
       "      <td>bolligen</td>\n",
       "      <td>bern</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2122 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id         location   age location_city location_state   \n",
       "2         13.0    n/a, n/a, n/a   NaN           NaN            NaN  \\\n",
       "6      13426.0        ottawa, ,   NaN        ottawa            NaN   \n",
       "32        17.0       seattle, ,  27.0       seattle            NaN   \n",
       "49      3087.0   albuquerque, ,   NaN   albuquerque            NaN   \n",
       "72      9776.0        humble, ,  38.0        humble            NaN   \n",
       "...        ...              ...   ...           ...            ...   \n",
       "67797  59467.0   lisbon, maine,  36.0        lisbon          maine   \n",
       "67929  59607.0       houston, ,   NaN       houston            NaN   \n",
       "67930  59608.0     sammamish, ,   NaN     sammamish            NaN   \n",
       "68058  59762.0       calgary, ,   NaN       calgary            NaN   \n",
       "68068  59776.0  bolligen, bern,  24.0      bolligen           bern   \n",
       "\n",
       "      location_country  \n",
       "2                  NaN  \n",
       "6                  NaN  \n",
       "32                 NaN  \n",
       "49                 NaN  \n",
       "72                 NaN  \n",
       "...                ...  \n",
       "67797              NaN  \n",
       "67929              NaN  \n",
       "67930              NaN  \n",
       "68058              NaN  \n",
       "68068              NaN  \n",
       "\n",
       "[2122 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[users['location_country'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d10759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                23\n",
       "location                0\n",
       "age                 27833\n",
       "location_city         101\n",
       "location_state       3185\n",
       "location_country     2122\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded04254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2139/3274669727.py:5: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
      "/tmp/ipykernel_2139/3274669727.py:5: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n"
     ]
    }
   ],
   "source": [
    "modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "location_list = []\n",
    "for location in modify_location:\n",
    "    try:\n",
    "        right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "        location_list.append(right_location)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "898a987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ottawa, ontario, canada',\n",
       " 'seattle, washington, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'humble, texas, usa',\n",
       " 'aloha, oregon, usa',\n",
       " 'pearland, texas, usa',\n",
       " 'sarasota, florida, usa',\n",
       " 'west springfield, massachusetts, usa',\n",
       " 'west linn, oregon, usa',\n",
       " 'north fort myers, florida, usa',\n",
       " 'coconut grove, florida, usa',\n",
       " 'mercer island, washington, usa',\n",
       " 'mercer island, washington, usa',\n",
       " 'de soto, missouri, usa',\n",
       " 'vigo, pontevedra, spain',\n",
       " 'carmichael, california, usa',\n",
       " 'chicago, illinois, usa',\n",
       " 'kuala lumpur, kuala lumpur, malaysia',\n",
       " 'tucson, arizona, usa',\n",
       " 'binghamton, new york, usa',\n",
       " 'yarmouth, nova scotia, canada',\n",
       " 'patterson lakes, victoria, australia',\n",
       " 'tucson, arizona, usa',\n",
       " 'manchester, england, united kingdom',\n",
       " 'cotati, california, usa',\n",
       " 'tualatin, oregon, usa',\n",
       " 'san francisco, california, usa',\n",
       " 'chesterfield, missouri, usa',\n",
       " 'brooklyn, new york, usa',\n",
       " 'oxford, england, united kingdom',\n",
       " 'anchorage, alaska, usa',\n",
       " 'chicago, illinois, usa',\n",
       " 'molalla, oregon, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'sahuarita, arizona, usa',\n",
       " 'fredericton, new brunswick, canada',\n",
       " 'cascade, colorado, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'bethel, connecticut, usa',\n",
       " 'halifax, nova scotia, canada',\n",
       " 'san marcos, california, usa',\n",
       " 'manchester, england, united kingdom',\n",
       " 'new bern, north carolina, usa',\n",
       " 'monroe, washington, usa',\n",
       " 'crystal lake, illinois, usa',\n",
       " 'little falls, new york, usa',\n",
       " 'altus, oklahoma, usa',\n",
       " 'houston, texas, usa',\n",
       " 'san diego, california, usa',\n",
       " 'redlands, california, usa',\n",
       " 'bluffton, ohio, usa',\n",
       " 'mathews, virginia, usa',\n",
       " 'rockland, maine, usa',\n",
       " 'hollister, california, usa',\n",
       " 'tucson, arizona, usa',\n",
       " 'kansas city, missouri, usa',\n",
       " 'greenville, south carolina, usa',\n",
       " 'weston, florida, usa',\n",
       " 'bellevue, washington, usa',\n",
       " 'leduc, alberta, canada',\n",
       " 'newport beach, california, usa',\n",
       " 'monroe, washington, usa',\n",
       " 'georgetown, ontario, canada',\n",
       " 'chicago, illinois, usa',\n",
       " 'halifax, nova scotia, canada',\n",
       " 'prague, n/a, czech republic',\n",
       " 'flint, michigan, usa',\n",
       " 'bourbonnais, illinois, usa',\n",
       " 'north wales, pennsylvania, usa',\n",
       " 'tustin, california, usa',\n",
       " 'gardiner, maine, usa',\n",
       " 'saint louis, missouri, usa',\n",
       " 'lancaster, pennsylvania, usa',\n",
       " 'temple, texas, usa',\n",
       " 'calgary, alberta, canada',\n",
       " 'columbus, ohio, usa',\n",
       " 'carmichael, california, usa',\n",
       " 'kenmore, washington, usa',\n",
       " 'dyersburg, tennessee, usa',\n",
       " 'college park, maryland, usa',\n",
       " 'valencia, valencia, spain',\n",
       " 'chicago, illinois, usa',\n",
       " 'irvine, california, usa',\n",
       " 'los gatos, california, usa',\n",
       " 'zeeland, michigan, usa',\n",
       " 'mesa, arizona, usa',\n",
       " 'santa barbara, california, usa',\n",
       " 'boise, idaho, usa',\n",
       " 'brantford, ontario, canada',\n",
       " 'portales, new mexico, usa',\n",
       " 'lexington, kentucky, usa',\n",
       " 'san luis obispo, california, usa',\n",
       " 'fairbanks, alaska, usa',\n",
       " 'fulton, missouri, usa',\n",
       " 'lagrange, georgia, usa',\n",
       " 'sonora, california, usa',\n",
       " 'austin, texas, usa',\n",
       " 'rochester, new york, usa',\n",
       " 'jacksonville, florida, usa',\n",
       " 'jacksonville, florida, usa',\n",
       " 'minneapolis, minnesota, usa',\n",
       " 'st. louis, missouri, usa',\n",
       " 'montreal, quebec, canada',\n",
       " 'chula vista, california, usa',\n",
       " 'singapore, n/a, singapore',\n",
       " 'woodstock, georgia, usa',\n",
       " 'markham, ontario, canada',\n",
       " 'fairfax, virginia, usa',\n",
       " 'tacoma, washington, usa',\n",
       " 'cambridge, massachusetts, usa',\n",
       " 'apopka, florida, usa',\n",
       " 'mannheim, baden-wuerttemberg, germany',\n",
       " 'crystal lake, illinois, usa',\n",
       " 'vienna, vienna, austria',\n",
       " 'el cajon, california, usa',\n",
       " 'new york, new york, usa',\n",
       " 'long beach, california, usa',\n",
       " 'spokane, washington, usa',\n",
       " 'didsbury, alberta, canada',\n",
       " 'lynchburg, virginia, usa',\n",
       " 'lagos, n/a, nigeria',\n",
       " 'salt lake city, utah, usa',\n",
       " 'sacramento, california, usa',\n",
       " 'cheriton, virginia, usa',\n",
       " 'elizabeth city, north carolina, usa',\n",
       " 'chattanooga, tennessee, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'san diego, california, usa',\n",
       " 'liverpool, england, united kingdom',\n",
       " 'santa monica, california, usa',\n",
       " 'rowlett, texas, usa',\n",
       " 'vallejo, california, usa',\n",
       " 'los angeles, california, usa',\n",
       " 'las vegas, nevada, usa',\n",
       " 'urbana, illinois, usa',\n",
       " 'houma, louisiana, usa',\n",
       " 'highlands ranch, colorado, usa',\n",
       " 'chicago, illinois, usa',\n",
       " 'san diego, california, usa',\n",
       " 'reno, nevada, usa',\n",
       " 'bloomery, west virginia, usa',\n",
       " 'hamilton, ontario, canada',\n",
       " 'somerset, kentucky, usa',\n",
       " 'solon, iowa, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'sacramento, california, usa',\n",
       " 'northglenn, colorado, usa',\n",
       " 'bronx, new york, usa',\n",
       " 'fredericton, new brunswick, canada',\n",
       " 'boston, massachusetts, usa',\n",
       " 'arlington, virginia, usa',\n",
       " 'pelham, new hampshire, usa',\n",
       " 'bay village, ohio, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'grosse pointe farms, michigan, usa',\n",
       " 'orlando, florida, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'gladstone, oregon, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'douglasville, georgia, usa',\n",
       " 'edmonton, alberta, canada',\n",
       " 'denver, colorado, usa',\n",
       " 'houston, texas, usa',\n",
       " 'colton, california, usa',\n",
       " 'walled lake, michigan, usa',\n",
       " 'raleigh, north carolina, usa',\n",
       " 'berkeley, california, usa',\n",
       " 'citronelle, alabama, usa',\n",
       " 'iowa city, iowa, usa',\n",
       " 'bend, oregon, usa',\n",
       " 'philadelphia, pennsylvania, usa',\n",
       " 'rochester, new york, usa',\n",
       " 'tulsa, oklahoma, usa',\n",
       " 'milano, lombardia, italy',\n",
       " 'oakland, california, usa',\n",
       " 'kelowna, british columbia, canada',\n",
       " 'round rock, texas, usa',\n",
       " 'freeport, illinois, usa',\n",
       " 'milford, new hampshire, usa',\n",
       " 'killeen, texas, usa',\n",
       " 'ocean springs, mississippi, usa',\n",
       " 'buffalo grove, illinois, usa',\n",
       " 'somewhere, texas, usa',\n",
       " 'corbin, kentucky, usa',\n",
       " 'fredericton, new brunswick, canada',\n",
       " 'huntington beach, california, usa',\n",
       " 'king of prussia, pennsylvania, usa',\n",
       " 'ithaca, new york, usa',\n",
       " 'newington, connecticut, usa',\n",
       " 'leroy, new york, usa',\n",
       " 'kelowna, british columbia, canada',\n",
       " 'madrid, madrid, spain',\n",
       " 'toronto, ontario, canada',\n",
       " 'barcelona, catalunya, spain',\n",
       " 'redding, california, usa',\n",
       " 'cologne, nordrhein-westfalen, germany',\n",
       " 'sheboygan, wisconsin, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'great barrington, massachusetts, usa',\n",
       " 'webster groves, missouri, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'georgetown, ontario, canada',\n",
       " 'woodstock, georgia, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'melbourne, victoria, australia',\n",
       " 'miami, florida, usa',\n",
       " 'middleboro, massachusetts, usa',\n",
       " 'mahwah, new jersey, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'tolland, connecticut, usa',\n",
       " 'charlotte, north carolina, usa',\n",
       " 'bradford, england, united kingdom',\n",
       " 'beaverton, oregon, usa',\n",
       " 'miami, florida, usa',\n",
       " 'choctaw, oklahoma, usa',\n",
       " 'bucharest, n/a, romania',\n",
       " 'new orleans, louisiana, usa',\n",
       " 'alpharetta, georgia, usa',\n",
       " 'augusta, georgia, usa',\n",
       " 'lenexa, kansas, usa',\n",
       " 'springfield, missouri, usa',\n",
       " 'newport coast, california, usa',\n",
       " 'baldwin, new york, usa',\n",
       " 'berkley, michigan, usa',\n",
       " 'port coquitlam, british columbia, canada',\n",
       " 'irvine, california, usa',\n",
       " 'hanahan, south carolina, usa',\n",
       " 'louisville, kentucky, usa',\n",
       " 'fairfield, california, usa',\n",
       " 'kincardine, ontario, canada',\n",
       " 'bridgewater, new jersey, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'salt lake city, utah, usa',\n",
       " 'brooklyn, new york, usa',\n",
       " 'santee, california, usa',\n",
       " 'santa rosa, california, usa',\n",
       " 'salem, oregon, usa',\n",
       " 'st. petersburg, florida, usa',\n",
       " 'williston park, new york, usa',\n",
       " 'spring creek, nevada, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'sacramento, california, usa',\n",
       " 'calgary, alberta, canada',\n",
       " 'middle island, new york, usa',\n",
       " 'el cajon, california, usa',\n",
       " 'marysville, washington, usa',\n",
       " 'orlando, florida, usa',\n",
       " 'boise, idaho, usa',\n",
       " 'lakeland, florida, usa',\n",
       " 'pittsburgh, pennsylvania, usa',\n",
       " 'pontiac, michigan, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'singapore, n/a, singapore',\n",
       " 'potomac falls, virginia, usa',\n",
       " 'belvidere, illinois, usa',\n",
       " 'aptos, california, usa',\n",
       " 'des moines, iowa, usa',\n",
       " 'torino, piemonte, italy',\n",
       " 'deventer, overijssel, netherlands',\n",
       " 'san antonio, texas, usa',\n",
       " 'eustis, florida, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'kalamazoo, michigan, usa',\n",
       " 'detroit, michigan, usa',\n",
       " 'edmonds, washington, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'modesto, california, usa',\n",
       " 'drayton valley, alberta, canada',\n",
       " 'caldwell, idaho, usa',\n",
       " 'springfield, missouri, usa',\n",
       " 'exton, pennsylvania, usa',\n",
       " 'saskatoon, saskatchewan, canada',\n",
       " 'bristol, england, united kingdom',\n",
       " 'new orleans, louisiana, usa',\n",
       " 'bristol, england, united kingdom',\n",
       " 'douglasville, georgia, usa',\n",
       " 'donostia, gipuzkoa, spain',\n",
       " 'irvine, california, usa',\n",
       " 'somerville, massachusetts, usa',\n",
       " 'hamilton, ontario, canada',\n",
       " 'oak harbor, washington, usa',\n",
       " 'caddo gap, arkansas, usa',\n",
       " 'ocala, florida, usa',\n",
       " 'simsbury, connecticut, usa',\n",
       " 'hartford, connecticut, usa',\n",
       " 'north oaks, minnesota, usa',\n",
       " 'elkton, maryland, usa',\n",
       " 'wrightstown, new jersey, usa',\n",
       " 'birmingham, alabama, usa',\n",
       " 'camdenton, missouri, usa',\n",
       " 'medowie, new south wales, australia',\n",
       " 'lakeland, florida, usa',\n",
       " 'modesto, california, usa',\n",
       " 'richmond, virginia, usa',\n",
       " 'quincy, massachusetts, usa',\n",
       " 'sacramento, california, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'aurora, colorado, usa',\n",
       " 'san diego, california, usa',\n",
       " 'cambridge, massachusetts, usa',\n",
       " 'santa cruz, california, usa',\n",
       " 'alabaster, alabama, usa',\n",
       " 'west valley city, utah, usa',\n",
       " 'san mateo, california, usa',\n",
       " 'florissant, missouri, usa',\n",
       " 'eagle river, alaska, usa',\n",
       " 'hamilton, ontario, canada',\n",
       " 'beaverton, oregon, usa',\n",
       " 'boston, massachusetts, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'oakville, ontario, canada',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'lynchburg, virginia, usa',\n",
       " 'irvine, california, usa',\n",
       " 'orlando, florida, usa',\n",
       " 'houston, texas, usa',\n",
       " 'hartford, connecticut, usa',\n",
       " 'freeburg, pennsylvania, usa',\n",
       " 'dearborn, michigan, usa',\n",
       " 'georgetown, ontario, canada',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'new bern, north carolina, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'new windsor, new york, usa',\n",
       " 'chicago, illinois, usa',\n",
       " 'saskatoon, saskatchewan, canada',\n",
       " 'kennesaw, georgia, usa',\n",
       " 'lakewood, colorado, usa',\n",
       " 'san diego, california, usa',\n",
       " 'herndon, virginia, usa',\n",
       " 'henderson, nevada, usa',\n",
       " 'colbert, oklahoma, usa',\n",
       " 'atlanta, georgia, usa',\n",
       " 'rockaway, new jersey, usa',\n",
       " 'new york city, new york, usa',\n",
       " 'orlando, florida, usa',\n",
       " 'woburn, massachusetts, usa',\n",
       " 'marysville, washington, usa',\n",
       " 'south saint paul, minnesota, usa',\n",
       " 'kenmore, washington, usa',\n",
       " 'fresno, california, usa',\n",
       " 'appleton, wisconsin, usa',\n",
       " 'del mar, california, usa',\n",
       " 'louisville, kentucky, usa',\n",
       " 'san diego, california, usa',\n",
       " 'odessa, florida, usa',\n",
       " 'melton mowbray, england, united kingdom',\n",
       " 'greenbelt, maryland, usa',\n",
       " 'rockford, illinois, usa',\n",
       " 'three rivers, california, usa',\n",
       " 'smyrna, georgia, usa',\n",
       " 'mississauga, ontario, canada',\n",
       " 'the woodlands, texas, usa',\n",
       " 'brooklyn, new york, usa',\n",
       " 'beaverton, oregon, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'san diego, california, usa',\n",
       " 'fort thomas, kentucky, usa',\n",
       " 'new port richey, florida, usa',\n",
       " 'charleston, south carolina, usa',\n",
       " 'auburn, washington, usa',\n",
       " 'boston, massachusetts, usa',\n",
       " 'san antonio, texas, usa',\n",
       " 'romeoville, illinois, usa',\n",
       " 'edmonton, alberta, canada',\n",
       " 'seattle, washington, usa',\n",
       " 'louisville, kentucky, usa',\n",
       " 'kingston, ontario, canada',\n",
       " 'portland, oregon, usa',\n",
       " 'los angeles, california, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'manotick, ontario, canada',\n",
       " 'rock hill, south carolina, usa',\n",
       " 'madison, wisconsin, usa',\n",
       " 'kalamazoo, michigan, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'delft, zuid holland, netherlands',\n",
       " 'reynoldsburg, ohio, usa',\n",
       " 'buffalo, new york, usa',\n",
       " 'quincy, massachusetts, usa',\n",
       " 'palatine, illinois, usa',\n",
       " 'houston, texas, usa',\n",
       " 'plaistow, new hampshire, usa',\n",
       " 'calgary, alberta, canada',\n",
       " 'toronto, ontario, canada',\n",
       " 'aurora, colorado, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'prospect, kentucky, usa',\n",
       " 'olivehurst, california, usa',\n",
       " 'alvin, texas, usa',\n",
       " 'grosse pointe, michigan, usa',\n",
       " 'chicago, illinois, usa',\n",
       " 'bradenton, florida, usa',\n",
       " 'cleveland, ohio, usa',\n",
       " 'angleton, texas, usa',\n",
       " 'rochester, new york, usa',\n",
       " 'tigard, oregon, usa',\n",
       " 'topeka, kansas, usa',\n",
       " 'omaha, nebraska, usa',\n",
       " 'exton, pennsylvania, usa',\n",
       " 'hillsboro, oregon, usa',\n",
       " 'fort myers beach, florida, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'fredericton, new brunswick, canada',\n",
       " 'windsor, ontario, canada',\n",
       " 'waukon, iowa, usa',\n",
       " 'sarasota, florida, usa',\n",
       " 'augusta, georgia, usa',\n",
       " 'chesapeake, virginia, usa',\n",
       " 'spokane, washington, usa',\n",
       " 'la jolla, california, usa',\n",
       " 'westbank, british columbia, canada',\n",
       " 'lynchburg, virginia, usa',\n",
       " 'santa monica, california, usa',\n",
       " 'portola valley, california, usa',\n",
       " 'chicago, illinois, usa',\n",
       " 'vienna, vienna, austria',\n",
       " 'richland, washington, usa',\n",
       " 'bullhead city, arizona, usa',\n",
       " 'malvern, pennsylvania, usa',\n",
       " 'willow creek, california, usa',\n",
       " 'letchworth garden city, england, united kingdom',\n",
       " 'knoxville, tennessee, usa',\n",
       " 'minneapolis, minnesota, usa',\n",
       " 'bloomington, indiana, usa',\n",
       " 'lakeville, minnesota, usa',\n",
       " 'buffalo, new york, usa',\n",
       " 'arlington, virginia, usa',\n",
       " 'raleigh, north carolina, usa',\n",
       " 'troy, michigan, usa',\n",
       " 'livonia, michigan, usa',\n",
       " 'san diego, california, usa',\n",
       " 'kirkwood, missouri, usa',\n",
       " 'baton rouge, louisiana, usa',\n",
       " 'guadalajara, jalisco, mexico',\n",
       " 'cottonwood, california, usa',\n",
       " 'houston, texas, usa',\n",
       " 'calgary, alberta, canada',\n",
       " 'pacifica, california, usa',\n",
       " 'austin, texas, usa',\n",
       " 'kitchener, ontario, canada',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'san francisco, california, usa',\n",
       " 'west warwick, rhode island, canada',\n",
       " 'christchurch, canterbury, new zealand',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'los angeles, california, usa',\n",
       " 'st. paul, minnesota, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'topeka, kansas, usa',\n",
       " 'blackwood, new jersey, usa',\n",
       " 'rome, lazio, italy',\n",
       " 'saint paul, minnesota, usa',\n",
       " 'kalamazoo, michigan, usa',\n",
       " 'austin, texas, usa',\n",
       " 'leroy, new york, usa',\n",
       " 'london, england, united kingdom',\n",
       " 'charleston, south carolina, usa',\n",
       " 'austin, texas, usa',\n",
       " 'staten island, new york, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'cochrane, alberta, canada',\n",
       " 'indianapolis, indiana, usa',\n",
       " 'south ohio, nova scotia, canada',\n",
       " 'carnegie, pennsylvania, usa',\n",
       " 'wayzata, minnesota, usa',\n",
       " 'charleston, south carolina, usa',\n",
       " 'kamloops, british columbia, canada',\n",
       " 'norfolk, virginia, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'nuku`alofa, n/a, tonga',\n",
       " 'east northport, new york, usa',\n",
       " 'hamilton, ontario, canada',\n",
       " 'gardena, california, usa',\n",
       " 'murphysboro, illinois, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'portland, oregon, usa',\n",
       " 'oshkosh, wisconsin, usa',\n",
       " 'tofino, british columbia, canada',\n",
       " 'santa barbara, california, usa',\n",
       " 'powell river, british columbia, canada',\n",
       " 'tualatin, oregon, usa',\n",
       " 'colchester, england, united kingdom',\n",
       " 'houston, texas, usa',\n",
       " 'lexington, kentucky, usa',\n",
       " 'skippack, pennsylvania, usa',\n",
       " 'tallahassee, florida, usa',\n",
       " 'minneapolis, minnesota, usa',\n",
       " 'hamilton, ontario, canada',\n",
       " 'los angeles, california, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'southampton, england, united kingdom',\n",
       " 'new bern, north carolina, usa',\n",
       " 'lawrence, kansas, usa',\n",
       " 'san diego, california, usa',\n",
       " 'sydney, new south wales, australia',\n",
       " 'des moines, iowa, usa',\n",
       " 'parkville, victoria, australia',\n",
       " 'daytona beach, florida, usa',\n",
       " 'louisville, kentucky, usa',\n",
       " 'san diego, california, usa',\n",
       " 'yuma, arizona, usa',\n",
       " 'tucson, arizona, usa',\n",
       " 'barcelona, catalunya, spain',\n",
       " 'joplin, missouri, usa',\n",
       " 'surrey, british columbia, canada',\n",
       " 'scottdale, pennsylvania, usa',\n",
       " 'mercer island, washington, usa',\n",
       " 'wichita, kansas, usa',\n",
       " 'chicago, illinois, usa',\n",
       " 'fallbrook, california, usa',\n",
       " 'arlington, virginia, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'pittsburgh, pennsylvania, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'decatur, georgia, usa',\n",
       " 'fairbanks, alaska, usa',\n",
       " 'minneapolis, minnesota, usa',\n",
       " 'golden, colorado, usa',\n",
       " 'st louis, missouri, usa',\n",
       " 'richmond hill, ontario, canada',\n",
       " 'murrieta, california, usa',\n",
       " 'atchison, kansas, usa',\n",
       " 'lacey, washington, usa',\n",
       " 'gloucester, massachusetts, usa',\n",
       " 'dallas, texas, usa',\n",
       " 'kenner, louisiana, usa',\n",
       " 'chilliwack, british columbia, canada',\n",
       " 'new freedom, pennsylvania, usa',\n",
       " 'berkeley, california, usa',\n",
       " 'st. louis, missouri, usa',\n",
       " 'new berlin, wisconsin, usa',\n",
       " 'regina, saskatchewan, canada',\n",
       " 'akron, ohio, usa',\n",
       " 'lexington, kentucky, usa',\n",
       " 'bettendorf, iowa, usa',\n",
       " 'beaverton, oregon, usa',\n",
       " 'lethbridge, alberta, canada',\n",
       " 'los angeles, california, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'rochester, new york, usa',\n",
       " 'burnaby, british columbia, canada',\n",
       " 'danville, california, usa',\n",
       " 'st. louis, missouri, usa',\n",
       " 'miami, florida, usa',\n",
       " 'gig harbor, washington, usa',\n",
       " 'baldwin, new york, usa',\n",
       " 'cedar rapids, iowa, usa',\n",
       " 'canton, ohio, usa',\n",
       " 'superior, wisconsin, usa',\n",
       " 'melbourne, victoria, australia',\n",
       " 'lakeside, california, usa',\n",
       " 'manchester, england, united kingdom',\n",
       " 'houston, texas, usa',\n",
       " 'livermore, california, usa',\n",
       " 'richmond, virginia, usa',\n",
       " 'oakland, california, usa',\n",
       " 'london, england, united kingdom',\n",
       " 'mountlake terrace, washington, usa',\n",
       " 'cambridge, massachusetts, usa',\n",
       " 'metairie, louisiana, usa',\n",
       " 'broken arrow, oklahoma, usa',\n",
       " 'charlotte, north carolina, usa',\n",
       " 'summerfield, florida, usa',\n",
       " 'perry hall, maryland, usa',\n",
       " 'la ronge, saskatchewan, canada',\n",
       " 'cornwall, ontario, canada',\n",
       " 'sugar land, texas, usa',\n",
       " 'waltham, massachusetts, usa',\n",
       " 'rosamond, california, usa',\n",
       " 'allston, massachusetts, usa',\n",
       " 'trumbull, connecticut, usa',\n",
       " 'annapolis, maryland, usa',\n",
       " 'johnstown, pennsylvania, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'north miami beach, florida, usa',\n",
       " 'worcester, massachusetts, usa',\n",
       " 'coquitlam, british columbia, canada',\n",
       " 'huntsville, alabama, usa',\n",
       " 'cheyenne, wyoming, usa',\n",
       " 'st. catharines, ontario, canada',\n",
       " 'courtenay, british columbia, canada',\n",
       " 'campbell river, british columbia, canada',\n",
       " 'edinburgh, scotland, united kingdom',\n",
       " 'warrensburg, missouri, usa',\n",
       " 'mountain view, california, usa',\n",
       " 'valley center, kansas, usa',\n",
       " 'dumfries, virginia, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'toronto, ontario, canada',\n",
       " 'norton, massachusetts, usa',\n",
       " 'abington, pennsylvania, usa',\n",
       " 'napa, california, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'hattiesburg, mississippi, usa',\n",
       " 'tarentum, pennsylvania, usa',\n",
       " 'villa ridge, missouri, usa',\n",
       " 'poway, california, usa',\n",
       " 'las vegas, nevada, usa',\n",
       " 'san diego, california, usa',\n",
       " 'charleston, south carolina, usa',\n",
       " 'calgary, alberta, canada',\n",
       " 'salem, oregon, usa',\n",
       " 'san diego, california, usa',\n",
       " 'carlsbad, california, usa',\n",
       " 'denver, colorado, usa',\n",
       " 'lakewood, colorado, usa',\n",
       " 'austin, texas, usa',\n",
       " 'davis, california, usa',\n",
       " 'burnaby, british columbia, canada',\n",
       " 'easton, pennsylvania, usa',\n",
       " 'deventer, overijssel, netherlands',\n",
       " 'chicago, illinois, usa',\n",
       " 'montclair, new jersey, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'pensacola, florida, usa',\n",
       " 'tucson, arizona, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'norfolk, virginia, usa',\n",
       " 'temecula, california, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'seattle, washington, usa',\n",
       " 'chesapeake, virginia, usa',\n",
       " 'royersford, pennsylvania, usa',\n",
       " 'modesto, california, usa',\n",
       " 'kessel-lo, n/a, belgium',\n",
       " 'black creek, british columbia, canada',\n",
       " 'paris, ile de france, france',\n",
       " 'paris, ile de france, france',\n",
       " 'paris, ile de france, france',\n",
       " 'st. louis, missouri, usa',\n",
       " 'berwyn heights, maryland, usa',\n",
       " 'edmonton, alberta, canada',\n",
       " 'columbia heights, minnesota, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'merrillville, indiana, usa',\n",
       " 'palo alto, california, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'pasadena, california, usa',\n",
       " 'raleigh, north carolina, usa',\n",
       " 'orlando, florida, usa',\n",
       " 'sterling, virginia, usa',\n",
       " 'la quinta, california, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'bay minette, alabama, usa',\n",
       " 'moline, illinois, usa',\n",
       " 'san antonio, texas, usa',\n",
       " 'fairbanks, alaska, usa',\n",
       " 'raleigh, north carolina, usa',\n",
       " 'singapore, n/a, singapore',\n",
       " 'los angeles, california, usa',\n",
       " 'little neck, new  york, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'cupertino, california, usa',\n",
       " 'belleville, illinois, usa',\n",
       " 'halifax, nova scotia, canada',\n",
       " 'greensburg, pennsylvania, usa',\n",
       " 'ithaca, new york, usa',\n",
       " 'pueblo, colorado, usa',\n",
       " 'aylmer, quebec, canada',\n",
       " 'omaha, nebraska, usa',\n",
       " 'san marcos, california, usa',\n",
       " 'syracuse, new york, usa',\n",
       " 'burlington, ontario, canada',\n",
       " 'jamaica plain, massachusetts, usa',\n",
       " 'bristol, england, united kingdom',\n",
       " 'south portland, maine, usa',\n",
       " 'monte vista, colorado, usa',\n",
       " 'anacortes, washington, usa',\n",
       " 'vanderhoof, british columbia, canada',\n",
       " 'munich, bayern, germany',\n",
       " 'muenchen, bayern, germany',\n",
       " 'staten island, new york, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'collierville, tennessee, usa',\n",
       " 'forty fort, , usa',\n",
       " 'jasper, missouri, usa',\n",
       " 'brookfield, wisconsin, usa',\n",
       " 'mansfield, pennsylvania, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'aloha, oregon, usa',\n",
       " 'dallas, texas, usa',\n",
       " 'simi valley, california, usa',\n",
       " 'dauphin, pennsylvania, usa',\n",
       " 'lexington, kentucky, usa',\n",
       " 'cary, north carolina, usa',\n",
       " 'berkeley, california, usa',\n",
       " 'encinitas, california, usa',\n",
       " 'youngstown, ohio, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'raleigh, north carolina, usa',\n",
       " 'los angeles, california, usa',\n",
       " 'omaha, nebraska, usa',\n",
       " 'torino, piemonte, italy',\n",
       " 'roma, lazio, italy',\n",
       " 'portland, oregon, usa',\n",
       " 'everett, washington, usa',\n",
       " 'bad axe, michigan, usa',\n",
       " 'boerne, texas, usa',\n",
       " 'boring, oregon, usa',\n",
       " 'baton rouge, louisiana, usa',\n",
       " 'millersburg, ohio, usa',\n",
       " 'lancaster, pennsylvania, usa',\n",
       " 'new york, new york, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'paris, ile de france, france',\n",
       " 'pleasant hill, california, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'new bern, north carolina, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'joplin, missouri, usa',\n",
       " 'seal beach, california, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'port hadlock, washington, usa',\n",
       " 'redding, california, usa',\n",
       " 'lawrence, kansas, usa',\n",
       " 'anchorage, alaska, usa',\n",
       " 'fürth, bayern, germany',\n",
       " 'bremen, bremen, germany',\n",
       " 'napa, california, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'wolfville, nova scotia, canada',\n",
       " 'south bend, indiana, usa',\n",
       " 'evergreen, colorado, usa',\n",
       " 'joplin, missouri, usa',\n",
       " 'fontana, california, usa',\n",
       " 'grayslake, illinois, usa',\n",
       " 'surrey, british columbia, canada',\n",
       " 'melbourne, victoria, australia',\n",
       " 'toronto, ontario, canada',\n",
       " 'evanston, illinois, usa',\n",
       " 'kendall park, new jersey, usa',\n",
       " 'brownsville, pennsylvania, usa',\n",
       " 'harrisonville, missouri, usa',\n",
       " 'kansas city, missouri, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'roma, lazio, italy',\n",
       " 'lake oswego, oregon, usa',\n",
       " 'richmond, virginia, usa',\n",
       " 'marion, ohio, usa',\n",
       " 'alpharetta, georgia, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'houston, texas, usa',\n",
       " 'moline, illinois, usa',\n",
       " 'ulsan, south gyeongsang, south korea',\n",
       " 'vergennes, vermont, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'metairie, louisiana, usa',\n",
       " 'ciudad colón, san josé, costa rica',\n",
       " 'altadena, california, usa',\n",
       " 'albany, new york, usa',\n",
       " 'utrecht, utrecht, netherlands',\n",
       " 'calgary, alberta, canada',\n",
       " 'los angeles, california, usa',\n",
       " 'rotterdam, zuid-holland, netherlands',\n",
       " 'carlisle, pennsylvania, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'west hartford, connecticut, usa',\n",
       " 'san juan capistrano, california, usa',\n",
       " 'foster city, california, usa',\n",
       " 'san marcos, california, usa',\n",
       " 'brisbane, queensland, australia',\n",
       " 'comox, british columbia, canada',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'huntington beach, california, usa',\n",
       " 'tigard, oregon, usa',\n",
       " 'fremont, california, usa',\n",
       " 'marlborough, massachusetts, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'matamoras, pennsylvania, usa',\n",
       " 'new haven, connecticut, usa',\n",
       " 'maryville, tennessee, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'tallahassee, florida, usa',\n",
       " 'charleston, south carolina, usa',\n",
       " 'boerne, texas, usa',\n",
       " 'bothell, washington, usa',\n",
       " 'newbury park, california, usa',\n",
       " 'hixson, tennessee, usa',\n",
       " 'kansas city, missouri, usa',\n",
       " 'beaverton, oregon, usa',\n",
       " 'storm lake, iowa, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'palo alto, california, usa',\n",
       " 'addison, texas, usa',\n",
       " 'asheville, north carolina, usa',\n",
       " 'lawrence, kansas, usa',\n",
       " 'watertown, massachusetts, usa',\n",
       " 'twyford, berkshire, united kingdom',\n",
       " 'newark, delaware, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'gales ferry, connecticut, usa',\n",
       " 'los angeles, california, usa',\n",
       " 'waterloo, ontario, canada',\n",
       " 'new york, new york, usa',\n",
       " 'cleveland heights, ohio, usa',\n",
       " 'morrisville, north carolina, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'toronto, ontario, canada',\n",
       " 'deming, new mexico, usa',\n",
       " 'pensacola, florida, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'richmond, virginia, usa',\n",
       " 'syracuse, new york, usa',\n",
       " 'somerville, massachusetts, usa',\n",
       " 'arcata, california, usa',\n",
       " 'minneapolis, minnesota, usa',\n",
       " 'oakland, california, usa',\n",
       " 'berlin, berlin, germany',\n",
       " 'ludwigshafen am rhein, rheinland-pfalz, germany',\n",
       " 'chicago, illinois, usa',\n",
       " 'toledo, ohio, usa',\n",
       " 'akron, ohio, usa',\n",
       " 'hamilton, ontario, canada',\n",
       " 'augsburg, bayern, germany',\n",
       " 'hamburg, hamburg, germany',\n",
       " 'candelo, new south wales, australia',\n",
       " 'canberra, australian capital territory, australia',\n",
       " 'santa monica, california, usa',\n",
       " 'lancaster, pennsylvania, usa',\n",
       " 'north haven, connecticut, usa',\n",
       " 'bloomingdale, illinois, usa',\n",
       " 'eugene, oregon, usa',\n",
       " 'mt. pleasant, south carolina, usa',\n",
       " 'houma, louisiana, usa',\n",
       " 'east meadow, new york, usa',\n",
       " 'wien, wien, austria',\n",
       " 'nürnberg, bayern, germany',\n",
       " 'harrow, england, united kingdom',\n",
       " 'sydney, new south wales, australia',\n",
       " 'el cajon, california, usa',\n",
       " 'santa maria, california, usa',\n",
       " 'tucson, arizona, usa',\n",
       " 'charlotte, north carolina, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'apex, north carolina, usa',\n",
       " 'manchester, england, united kingdom',\n",
       " 'napa, california, usa',\n",
       " 'cranston, rhode island, usa',\n",
       " 'yorba linda, california, usa',\n",
       " 'calgary, alberta, canada',\n",
       " 'detroit, michigan, usa',\n",
       " 'milwaukie, oregon, usa',\n",
       " 'christchurch, canterbury, new zealand',\n",
       " 'oakland, california, usa',\n",
       " 'scottsdale, arizona, usa',\n",
       " 'albuquerque, new mexico, usa',\n",
       " 'edmonds, washington, usa',\n",
       " 'cary, north carolina, usa',\n",
       " 'amsterdam, noord-holland, netherlands',\n",
       " 'glendale, california, usa',\n",
       " 'asheville, north carolina, usa',\n",
       " 'dallas, texas, usa',\n",
       " 'st. charles, missouri, usa',\n",
       " 'roanoke, virginia, usa',\n",
       " 'port coquitlam, british columbia, canada',\n",
       " 'seattle, washington, usa',\n",
       " 'los angeles, california, usa',\n",
       " 'melbourne, victoria, australia',\n",
       " 'lewiston, maine, usa',\n",
       " 'lincoln, nebraska, usa',\n",
       " 'marysville, washington, usa',\n",
       " 'clio, michigan, usa',\n",
       " 'köln, nordrhein-westfalen, germany',\n",
       " 'tokyo, tokyo, japan',\n",
       " 'slocan park, british columbia, canada',\n",
       " 'delft, zuid holland, netherlands',\n",
       " 'greenfield park, quebec, canada',\n",
       " 'asheville, north carolina, usa',\n",
       " 'savannah, georgia, usa',\n",
       " 'baltimore, maryland, usa',\n",
       " 'guadalajara, jalisco, mexico',\n",
       " 'surrey, british columbia, canada',\n",
       " 'audubon, iowa, usa',\n",
       " 'virginia beach, virginia, usa',\n",
       " 'tsawwassen, british columbia, canada',\n",
       " 'fredericton, new brunswick, canada',\n",
       " 'halifax, nova scotia, canada',\n",
       " 'decatur, georgia, usa',\n",
       " 'saginaw, michigan, usa',\n",
       " 'barcelona, catalunya, spain',\n",
       " 'saint louis, missouri, usa',\n",
       " 'fair oaks, california, usa',\n",
       " 'fredericton, new brunswick, canada',\n",
       " 'milano, lombardia, italy',\n",
       " 'torino, piemonte, italy',\n",
       " 'padova, veneto, italy',\n",
       " 'naracoorte, south australia, australia',\n",
       " 'casper, wyoming, usa',\n",
       " 'cedar rapids, iowa, usa',\n",
       " 'long branch, new jersey, usa',\n",
       " 'harrisonville, missouri, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'bensenville, illinois, usa',\n",
       " 'burnsville, minnesota, usa',\n",
       " 'clementon, new jersey, usa',\n",
       " 'hamilton, ontario, canada',\n",
       " 'st. petersburg, florida, usa',\n",
       " 'cedar falls, iowa, usa',\n",
       " 'seattle, washington, usa',\n",
       " 'preston, england, united kingdom',\n",
       " 'sainte-foy, quebec, canada',\n",
       " 'montreal, quebec, canada',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'toronto, ontario, canada',\n",
       " 'the colony, texas, usa',\n",
       " 'indianapolis, indiana, usa',\n",
       " 'springfield, missouri, usa',\n",
       " 'harrisburg, pennsylvania, usa',\n",
       " 'montreal, quebec, canada',\n",
       " 'amsterdam, noord-holland, netherlands',\n",
       " 'milano, lombardia, italy',\n",
       " 'port washington, new york, usa',\n",
       " 'evanston, illinois, usa',\n",
       " 'the hague, n/a, netherlands',\n",
       " 'robbinsdale, minnesota, usa',\n",
       " 'clarksville, tennessee, usa',\n",
       " 'clinton township, michigan, usa',\n",
       " 'regina, saskatchewan, canada',\n",
       " 'knoxville, tennessee, usa',\n",
       " 'irvine, california, usa',\n",
       " 'lima, ohio, usa',\n",
       " 'cedar rapids, iowa, usa',\n",
       " 'st. paul, minnesota, usa',\n",
       " 'houston, texas, usa',\n",
       " 'chesterfield, missouri, usa',\n",
       " 'kitty hawk, north carolina, usa',\n",
       " 'oviedo, florida, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'miami, florida, usa',\n",
       " 'lake worth, florida, usa',\n",
       " 'martinez, california, usa',\n",
       " 'portales, new mexico, usa',\n",
       " 'texas city, texas, usa',\n",
       " 'irving, texas, usa',\n",
       " 'duncan, british columbia, canada',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'abbotsford, british columbia, canada',\n",
       " 'kansas city, missouri, usa',\n",
       " 'melbourne, victoria, australia',\n",
       " 'george town, penang, malaysia',\n",
       " 'bronx, new york, usa',\n",
       " 'windsor, ontario, canada',\n",
       " 'singapore, n/a, singapore',\n",
       " 'oak ridge, tennessee, usa',\n",
       " 'sault ste. marie, ontario, canada',\n",
       " 'lexington, kentucky, usa',\n",
       " 'richardson, texas, usa',\n",
       " 'brigham city, utah, usa',\n",
       " 'springfield, missouri, usa',\n",
       " 'vancouver, british columbia, canada',\n",
       " 'fort wayne, indiana, usa',\n",
       " 'burlington, ontario, canada',\n",
       " 'fountain valley, california, usa',\n",
       " 'ottawa, ontario, canada',\n",
       " 'christchurch, canterbury, new zealand',\n",
       " 'ottawa, ontario, canada',\n",
       " 'molalla, oregon, usa',\n",
       " 'los angeles, california, usa',\n",
       " 'stockton-on-tees, england, united kingdom',\n",
       " 'fredericton, new brunswick, canada',\n",
       " 'portland, oregon, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'new hope, minnesota, usa',\n",
       " 'limerick, pennsylvania, usa',\n",
       " 'cincinnati, ohio, usa',\n",
       " 'rapid city, south dakota, usa',\n",
       " 'new castle, delaware, usa',\n",
       " 'piermont, new york, usa',\n",
       " 'league city, texas, usa',\n",
       " 'firenze, toscana, italy',\n",
       " 'lancaster, pennsylvania, usa',\n",
       " 'wien, wien, austria',\n",
       " 'irvine, california, usa',\n",
       " 'brandon, florida, usa',\n",
       " 'treviso, veneto, italy',\n",
       " 'sandpoint, idaho, usa',\n",
       " 'singapore, n/a, singapore',\n",
       " 'hamilton, ontario, canada',\n",
       " 'roma, lazio, italy',\n",
       " 'agoura hills, california, usa',\n",
       " 'genova, liguria, italy',\n",
       " 'hamburg, hamburg, germany',\n",
       " 'sebastopol, california, usa',\n",
       " 'portland, oregon, usa',\n",
       " 'las vegas, nevada, usa',\n",
       " 'framingham, massachusetts, usa',\n",
       " 'white bear lake, minnesota, usa',\n",
       " 'wilsonville, oregon, usa',\n",
       " 'santa monica, california, usa',\n",
       " 'new york, new york, usa',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007270ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in location_list:\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e1bc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                23\n",
       "location                0\n",
       "age                 27833\n",
       "location_city         101\n",
       "location_state       1091\n",
       "location_country      273\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a363e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68092 68069\n"
     ]
    }
   ],
   "source": [
    "print(len(users),len(user2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02bbead6-88c8-4bd2-91dc-ef1510b195a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 인덱싱 처리된 데이터 조인\n",
    "context_df = ratings.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')\n",
    "train_df = train.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')\n",
    "test_df = test.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e7fdc",
   "metadata": {},
   "source": [
    "user_id와 isbn이 간단한 index로 바뀐 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e12c0145-4cab-4dad-bddb-f06ec6e9286a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "      <th>category</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>book_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>en</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>30.0</td>\n",
       "      <td>toronto</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>en</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>kingston, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kingston</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>en</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>comber, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comber</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>en</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>guelph, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>guelph</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>en</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306790</th>\n",
       "      <td>6313</td>\n",
       "      <td>129772</td>\n",
       "      <td>7</td>\n",
       "      <td>pismo beach, california, usa</td>\n",
       "      <td>28.0</td>\n",
       "      <td>pismo beach</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simon &amp; Schuster Audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>David Gardner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306791</th>\n",
       "      <td>1879</td>\n",
       "      <td>129773</td>\n",
       "      <td>6</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>dallas</td>\n",
       "      <td>texas</td>\n",
       "      <td>usa</td>\n",
       "      <td>['Humor']</td>\n",
       "      <td>Pocket Books</td>\n",
       "      <td>en</td>\n",
       "      <td>P.J. O'Rourke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306792</th>\n",
       "      <td>1879</td>\n",
       "      <td>129774</td>\n",
       "      <td>7</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>dallas</td>\n",
       "      <td>texas</td>\n",
       "      <td>usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lone Star Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Claude Dooley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306793</th>\n",
       "      <td>1879</td>\n",
       "      <td>129775</td>\n",
       "      <td>7</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>dallas</td>\n",
       "      <td>texas</td>\n",
       "      <td>usa</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>Kqed Books</td>\n",
       "      <td>en</td>\n",
       "      <td>Jeremy Lloyd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306794</th>\n",
       "      <td>1879</td>\n",
       "      <td>129776</td>\n",
       "      <td>10</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>dallas</td>\n",
       "      <td>texas</td>\n",
       "      <td>usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Map Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mapsco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306795 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id    isbn  rating                      location   age   \n",
       "0             0       0       4      timmins, ontario, canada   NaN  \\\n",
       "1             1       0       7      toronto, ontario, canada  30.0   \n",
       "2             2       0       8     kingston, ontario, canada   NaN   \n",
       "3             3       0       8       comber, ontario, canada   NaN   \n",
       "4             4       0       9       guelph, ontario, canada   NaN   \n",
       "...         ...     ...     ...                           ...   ...   \n",
       "306790     6313  129772       7  pismo beach, california, usa  28.0   \n",
       "306791     1879  129773       6            dallas, texas, usa  33.0   \n",
       "306792     1879  129774       7            dallas, texas, usa  33.0   \n",
       "306793     1879  129775       7            dallas, texas, usa  33.0   \n",
       "306794     1879  129776      10            dallas, texas, usa  33.0   \n",
       "\n",
       "       location_city location_state location_country       category   \n",
       "0            timmins        ontario           canada  ['Actresses']  \\\n",
       "1            toronto        ontario           canada  ['Actresses']   \n",
       "2           kingston        ontario           canada  ['Actresses']   \n",
       "3             comber        ontario           canada  ['Actresses']   \n",
       "4             guelph        ontario           canada  ['Actresses']   \n",
       "...              ...            ...              ...            ...   \n",
       "306790   pismo beach     california              usa            NaN   \n",
       "306791        dallas          texas              usa      ['Humor']   \n",
       "306792        dallas          texas              usa            NaN   \n",
       "306793        dallas          texas              usa    ['Fiction']   \n",
       "306794        dallas          texas              usa            NaN   \n",
       "\n",
       "                       publisher language           book_author  \n",
       "0          HarperFlamingo Canada       en  Richard Bruce Wright  \n",
       "1          HarperFlamingo Canada       en  Richard Bruce Wright  \n",
       "2          HarperFlamingo Canada       en  Richard Bruce Wright  \n",
       "3          HarperFlamingo Canada       en  Richard Bruce Wright  \n",
       "4          HarperFlamingo Canada       en  Richard Bruce Wright  \n",
       "...                          ...      ...                   ...  \n",
       "306790    Simon & Schuster Audio      NaN         David Gardner  \n",
       "306791              Pocket Books       en         P.J. O'Rourke  \n",
       "306792           Lone Star Books      NaN         Claude Dooley  \n",
       "306793                Kqed Books       en          Jeremy Lloyd  \n",
       "306794  American Map Corporation      NaN                Mapsco  \n",
       "\n",
       "[306795 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32d43034",
   "metadata": {},
   "source": [
    "age와 Category, Language등 결측값이 존재하는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "92a950b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 나머지 인덱스들도 숫자로 변환하는 작업을 수행한다.\n",
    "# 결측치도 숫자로 바꿔버린다.\n",
    "loc_city2idx = {v:k for k,v in enumerate(context_df['location_city'].unique())}\n",
    "loc_state2idx = {v:k for k,v in enumerate(context_df['location_state'].unique())}\n",
    "loc_country2idx = {v:k for k,v in enumerate(context_df['location_country'].unique())}\n",
    "loc_city2idx[np.nan] = np.nan\n",
    "loc_state2idx[np.nan] = np.nan\n",
    "loc_country2idx[np.nan] = np.nan\n",
    "loc_country2idx\n",
    "# loc_state2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "279fc80b-e7de-42e7-825a-b26494598778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['location_city'] = train_df['location_city'].map(loc_city2idx)\n",
    "train_df['location_state'] = train_df['location_state'].map(loc_state2idx)\n",
    "train_df['location_country'] = train_df['location_country'].map(loc_country2idx)\n",
    "test_df['location_city'] = test_df['location_city'].map(loc_city2idx)\n",
    "test_df['location_state'] = test_df['location_state'].map(loc_state2idx)\n",
    "test_df['location_country'] = test_df['location_country'].map(loc_country2idx)\n",
    "\n",
    "# age의 결측치는 평균으로 채운다. \n",
    "# train_df['age'] = train_df['age'].fillna(int(train_df['age'].mean()))\n",
    "# train_df['age'] = train_df['age'].apply(age_map)\n",
    "# test_df['age'] = test_df['age'].fillna(int(test_df['age'].mean()))\n",
    "# test_df['age'] = test_df['age'].apply(age_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "765f4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book 파트 인덱싱\n",
    "category2idx = {v:k for k,v in enumerate(context_df['category'].unique())}\n",
    "publisher2idx = {v:k for k,v in enumerate(context_df['publisher'].unique())}\n",
    "language2idx = {v:k for k,v in enumerate(context_df['language'].unique())}\n",
    "author2idx = {v:k for k,v in enumerate(context_df['book_author'].unique())}\n",
    "category2idx[np.nan] = np.nan\n",
    "publisher2idx[np.nan] = np.nan\n",
    "language2idx[np.nan] = np.nan\n",
    "author2idx[np.nan] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b206fc4f-18f9-47bb-9d3b-e6399b88086a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['category'] = train_df['category'].map(category2idx)\n",
    "train_df['publisher'] = train_df['publisher'].map(publisher2idx)\n",
    "train_df['language'] = train_df['language'].map(language2idx)\n",
    "train_df['book_author'] = train_df['book_author'].map(author2idx)\n",
    "test_df['category'] = test_df['category'].map(category2idx)\n",
    "test_df['publisher'] = test_df['publisher'].map(publisher2idx)\n",
    "test_df['language'] = test_df['language'].map(language2idx)\n",
    "test_df['book_author'] = test_df['book_author'].map(author2idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df4bde3f",
   "metadata": {},
   "source": [
    "모든 데이터가 숫자로 바뀐 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "201e1346-8f06-4633-8180-4e55c1037cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "      <th>category</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>book_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26761</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16495</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6225</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76694</th>\n",
       "      <td>7728</td>\n",
       "      <td>149565</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76695</th>\n",
       "      <td>47785</td>\n",
       "      <td>149566</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76696</th>\n",
       "      <td>4209</td>\n",
       "      <td>149567</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76697</th>\n",
       "      <td>40779</td>\n",
       "      <td>149568</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76698</th>\n",
       "      <td>1879</td>\n",
       "      <td>149569</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62058.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id    isbn  rating   age  location_city  location_state   \n",
       "0           13       0       0   NaN            NaN             NaN  \\\n",
       "1        13426       0       0   NaN          309.0             NaN   \n",
       "2        26761       1       0  40.0          309.0             0.0   \n",
       "3        16495       2       0  30.0          195.0            14.0   \n",
       "4         6225       3       0  39.0         2716.0            92.0   \n",
       "...        ...     ...     ...   ...            ...             ...   \n",
       "76694     7728  149565       0  39.0         3086.0             5.0   \n",
       "76695    47785  149566       0  37.0          323.0           104.0   \n",
       "76696     4209  149567       0   NaN           20.0            18.0   \n",
       "76697    40779  149568       0  48.0          210.0            66.0   \n",
       "76698     1879  149569       0  33.0           19.0            10.0   \n",
       "\n",
       "       location_country  category  publisher  language  book_author  \n",
       "0                   NaN       0.0        0.0       0.0          0.0  \n",
       "1                   NaN       0.0        0.0       0.0          0.0  \n",
       "2                   0.0       1.0        1.0       0.0          1.0  \n",
       "3                   1.0       2.0        2.0       0.0          2.0  \n",
       "4                   1.0       3.0        3.0       0.0          3.0  \n",
       "...                 ...       ...        ...       ...          ...  \n",
       "76694               1.0      73.0      310.0       0.0       1275.0  \n",
       "76695              18.0     985.0      108.0       2.0      10774.0  \n",
       "76696               1.0       3.0     7792.0       0.0      62056.0  \n",
       "76697              13.0       NaN     5050.0       NaN      62057.0  \n",
       "76698               1.0       6.0      224.0       0.0      62058.0  \n",
       "\n",
       "[76699 rows x 11 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a180462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'isbn', 'rating', 'age', 'location_city', 'location_state',\n",
       "       'location_country', 'category', 'publisher', 'language', 'book_author'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_columns = train_df.columns\n",
    "temp_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0f19c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer_mice = IterativeImputer(random_state=9)\n",
    "train_df = pd.DataFrame(imputer_mice.fit_transform(train_df)).applymap(lambda x:round(x))\n",
    "test_df = pd.DataFrame(imputer_mice.fit_transform(test_df)).applymap(lambda x:round(x))\n",
    "train_df.columns = temp_columns\n",
    "test_df.columns = temp_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9d454e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "      <th>category</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>book_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306790</th>\n",
       "      <td>6313</td>\n",
       "      <td>129772</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>1606</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>2171</td>\n",
       "      <td>0</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306791</th>\n",
       "      <td>1879</td>\n",
       "      <td>129773</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306792</th>\n",
       "      <td>1879</td>\n",
       "      <td>129774</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>796</td>\n",
       "      <td>10406</td>\n",
       "      <td>0</td>\n",
       "      <td>54713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306793</th>\n",
       "      <td>1879</td>\n",
       "      <td>129775</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6387</td>\n",
       "      <td>0</td>\n",
       "      <td>54714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306794</th>\n",
       "      <td>1879</td>\n",
       "      <td>129776</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>794</td>\n",
       "      <td>10407</td>\n",
       "      <td>0</td>\n",
       "      <td>54715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306795 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id    isbn  rating  age  location_city  location_state   \n",
       "0             0       0       4   37              0               0  \\\n",
       "1             1       0       7   30              1               0   \n",
       "2             2       0       8   37              2               0   \n",
       "3             3       0       8   37              3               0   \n",
       "4             4       0       9   37              4               0   \n",
       "...         ...     ...     ...  ...            ...             ...   \n",
       "306790     6313  129772       7   28           1606               5   \n",
       "306791     1879  129773       6   33             19              10   \n",
       "306792     1879  129774       7   33             19              10   \n",
       "306793     1879  129775       7   33             19              10   \n",
       "306794     1879  129776      10   33             19              10   \n",
       "\n",
       "        location_country  category  publisher  language  book_author  \n",
       "0                      0         0          0         0            0  \n",
       "1                      0         0          0         0            0  \n",
       "2                      0         0          0         0            0  \n",
       "3                      0         0          0         0            0  \n",
       "4                      0         0          0         0            0  \n",
       "...                  ...       ...        ...       ...          ...  \n",
       "306790                 1       324       2171         0         1272  \n",
       "306791                 1         7        222         0           69  \n",
       "306792                 1       796      10406         0        54713  \n",
       "306793                 1         3       6387         0        54714  \n",
       "306794                 1       794      10407         0        54715  \n",
       "\n",
       "[306795 rows x 11 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c0d853fe-40e5-4074-970c-6183169553cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = {\n",
    "    \"loc_city2idx\":loc_city2idx,\n",
    "    \"loc_state2idx\":loc_state2idx,\n",
    "    \"loc_country2idx\":loc_country2idx,\n",
    "    \"category2idx\":category2idx,\n",
    "    \"publisher2idx\":publisher2idx,\n",
    "    \"language2idx\":language2idx,\n",
    "    \"author2idx\":author2idx,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bd491a98-1a2f-4efb-abb7-188a1a60ebce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_train, context_test = train_df, test_df\n",
    "field_dims = np.array([len(user2idx), len(isbn2idx),\n",
    "                        6, len(idx['loc_city2idx']), len(idx['loc_state2idx']), len(idx['loc_country2idx']),\n",
    "                        len(idx['category2idx']), len(idx['publisher2idx']), len(idx['language2idx']), len(idx['author2idx'])], dtype=np.uint32)\n",
    "\n",
    "data = {\n",
    "        'train':context_train,\n",
    "        'test':context_test.drop(['rating'], axis=1),\n",
    "        'field_dims':field_dims,\n",
    "        'users':users,\n",
    "        'books':books,\n",
    "        'sub':sub,\n",
    "        'idx2user':idx2user,\n",
    "        'idx2isbn':idx2isbn,\n",
    "        'user2idx':user2idx,\n",
    "        'isbn2idx':isbn2idx,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "789c41df-964b-4f63-b8cd-99826457458a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68069, 149570,      6,  12265,   1594,    344,   4293,  11572,\n",
       "           27,  62059], dtype=uint32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "26b240cb-4158-430c-8a11-a99c48299bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def context_data_split(args, data):\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                                                    data['train'].drop(['rating'], axis=1),\n",
    "                                                    data['train']['rating'],\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=seed,\n",
    "                                                    shuffle=True\n",
    "                                                    )\n",
    "data['X_train'], data['X_valid'], data['y_train'], data['y_valid'] = X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f0c1fda6-b3b4-4b3e-a532-f6830df0a85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def context_data_loader(args, data):\n",
    "train_dataset = TensorDataset(torch.LongTensor(data['X_train'].values), torch.LongTensor(data['y_train'].values))\n",
    "valid_dataset = TensorDataset(torch.LongTensor(data['X_valid'].values), torch.LongTensor(data['y_valid'].values))\n",
    "test_dataset = TensorDataset(torch.LongTensor(data['test'].values))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=data_shuffle)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=data_shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "data['train_dataloader'], data['valid_dataloader'], data['test_dataloader'] = train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dc32d704-c67b-4178-8723-38e5e3c54fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Setting:\n",
    "    @staticmethod\n",
    "    def seed_everything(seed):\n",
    "        '''\n",
    "        [description]\n",
    "        seed 값을 고정시키는 함수입니다.\n",
    "\n",
    "        [arguments]\n",
    "        seed : seed 값\n",
    "        '''\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    def __init__(self):\n",
    "        now = time.localtime()\n",
    "        now_date = time.strftime('%Y%m%d', now)\n",
    "        now_hour = time.strftime('%X', now)\n",
    "        save_time = now_date + '_' + now_hour.replace(':', '')\n",
    "        self.save_time = save_time\n",
    "\n",
    "    def get_log_path(self, model):\n",
    "        '''\n",
    "        [description]\n",
    "        log file을 저장할 경로를 반환하는 함수입니다.\n",
    "\n",
    "        [arguments]\n",
    "        args : argparse로 입력받은 args 값으로 이를 통해 모델의 정보를 전달받습니다.\n",
    "\n",
    "        [return]\n",
    "        path : log file을 저장할 경로를 반환합니다.\n",
    "        이 때, 경로는 log/날짜_시간_모델명/ 입니다.\n",
    "        '''\n",
    "        path = f'./log/{self.save_time}_{model}/'\n",
    "        return path\n",
    "\n",
    "    def get_submit_filename(self, model):\n",
    "        '''\n",
    "        [description]\n",
    "        submit file을 저장할 경로를 반환하는 함수입니다.\n",
    "\n",
    "        [arguments]\n",
    "        args : argparse로 입력받은 args 값으로 이를 통해 모델의 정보를 전달받습니다.\n",
    "\n",
    "        [return]\n",
    "        filename : submit file을 저장할 경로를 반환합니다.\n",
    "        이 때, 파일명은 submit/날짜_시간_모델명.csv 입니다.\n",
    "        '''\n",
    "        path = self.make_dir(\"./submit/\")\n",
    "        filename = f'{path}{self.save_time}_{model}.csv'\n",
    "        return filename\n",
    "\n",
    "    def make_dir(self,path):\n",
    "        '''\n",
    "        [description]\n",
    "        경로가 존재하지 않을 경우 해당 경로를 생성하며, 존재할 경우 pass를 하는 함수입니다.\n",
    "\n",
    "        [arguments]\n",
    "        path : 경로\n",
    "\n",
    "        [return]\n",
    "        path : 경로\n",
    "        '''\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        else:\n",
    "            pass\n",
    "        return path\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, model, path):\n",
    "        \"\"\"\n",
    "        [description]\n",
    "        log file을 생성하는 클래스입니다.\n",
    "\n",
    "        [arguments]\n",
    "        args : argparse로 입력받은 args 값으로 이를 통해 모델의 정보를 전달받습니다.\n",
    "        path : log file을 저장할 경로를 전달받습니다.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.path = path\n",
    "\n",
    "        self.logger = logging.getLogger()\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        self.formatter = logging.Formatter('[%(asctime)s] - %(message)s')\n",
    "\n",
    "        self.file_handler = logging.FileHandler(self.path+'train.log')\n",
    "        self.file_handler.setFormatter(self.formatter)\n",
    "        self.logger.addHandler(self.file_handler)\n",
    "\n",
    "    def log(self, epoch, train_loss, valid_loss):\n",
    "        '''\n",
    "        [description]\n",
    "        log file에 epoch, train loss, valid loss를 기록하는 함수입니다.\n",
    "        이 때, log file은 train.log로 저장됩니다.\n",
    "\n",
    "        [arguments]\n",
    "        epoch : epoch\n",
    "        train_loss : train loss\n",
    "        valid_loss : valid loss\n",
    "        '''\n",
    "        message = f'epoch : {epoch}/{epochs} | train loss : {train_loss:.3f} | valid loss : {valid_loss:.3f}'\n",
    "        self.logger.info(message)\n",
    "\n",
    "    def close(self):\n",
    "        '''\n",
    "        [description]\n",
    "        log file을 닫는 함수입니다.\n",
    "        '''\n",
    "        self.logger.removeHandler(self.file_handler)\n",
    "        self.file_handler.close()\n",
    "\n",
    "# args는 초반에 다 지정해버렸기 때문에, 이 함수는 필요없다.\n",
    "#     def save_args(self):\n",
    "#         '''\n",
    "#         [description]\n",
    "#         model에 사용된 args를 저장하는 함수입니다.\n",
    "#         이 때, 저장되는 파일명은 model.json으로 저장됩니다.\n",
    "#         '''\n",
    "#         argparse_dict = self.args.__dict__\n",
    "\n",
    "#         with open(f'{self.path}/model.json', 'w') as f:\n",
    "#             json.dump(argparse_dict,f,indent=4)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "de6a8203-5f29-4d53-9031-cf5da749adbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "setting = Setting()\n",
    "\n",
    "log_path = setting.get_log_path(model)\n",
    "setting.make_dir(log_path)\n",
    "\n",
    "logger = Logger(model, log_path)\n",
    "# logger.save_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "54a1ff69-db0c-4b13-bd09-cc64e5390868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# factorization을 통해 얻은 feature를 embedding 합니다.\n",
    "class FeaturesEmbedding(nn.Module):\n",
    "    def __init__(self, field_dims: np.ndarray, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "# FM모델 등에서 활용되는 선형 결합 부분을 정의합니다.\n",
    "class FeaturesLinear(nn.Module):\n",
    "    def __init__(self, field_dims: np.ndarray, output_dim: int=1):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias\n",
    "\n",
    "\n",
    "# feature 사이의 상호작용을 효율적으로 계산합니다.\n",
    "class FactorizationMachine(nn.Module):\n",
    "    def __init__(self, reduce_sum:bool=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
    "        return 0.5 * ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a705a92b-1f70-4d26-856e-bd84f354e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachineModel(nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.field_dims = data['field_dims']\n",
    "        self.embedding = FeaturesEmbedding(self.field_dims, embed_dim)\n",
    "        self.linear = FeaturesLinear(self.field_dims)\n",
    "        self.fm = FactorizationMachine(reduce_sum=True)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.linear(x) + self.fm(self.embedding(x))\n",
    "        # return torch.sigmoid(x.squeeze(1))\n",
    "        return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dff18fb5-0c3e-4773-95ae-8ff64c95c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def models_load(args, data):\n",
    "model = FactorizationMachineModel(data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ddd32b0a-953b-4119-9027-f6b0fa68a31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.eps = 1e-6\n",
    "    def forward(self, x, y):\n",
    "        criterion = MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y)+self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "528eadb8-728a-41bb-a908-feccce791763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch = 0\n",
    "\n",
    "    for idx, data in enumerate(dataloader['valid_dataloader']):\n",
    "        x, y = data[0].to(device), data[1].to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y.float(), y_hat)\n",
    "        total_loss += loss.item()\n",
    "        batch +=1\n",
    "    valid_loss = total_loss/batch\n",
    "    return valid_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "80c7ff98-a259-4a58-8598-9a2bceb0f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, logger, setting):\n",
    "    print(model)\n",
    "    minimum_loss = 999999999\n",
    "    loss_fn = RMSELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch = 0\n",
    "\n",
    "        for idx, data in enumerate(dataloader['train_dataloader']):\n",
    "            x, y = data[0].to(device), data[1].to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y.float(), y_hat)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            batch +=1\n",
    "        valid_loss = valid(model, dataloader, loss_fn)\n",
    "        print(f'Epoch: {epoch+1}, Train_loss: {total_loss/batch:.3f}, valid_loss: {valid_loss:.3f}')\n",
    "        logger.log(epoch=epoch+1, train_loss=total_loss/batch, valid_loss=valid_loss)\n",
    "        if minimum_loss > valid_loss:\n",
    "            minimum_loss = valid_loss\n",
    "            os.makedirs(saved_model_path, exist_ok=True)\n",
    "            # torch.save(state_dict(), f'{saved_model_path}/{setting.save_time}_{model}_model.pt')\n",
    "    logger.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bbcf041d-f3d9-40b0-aa29-6824e0ee3288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FactorizationMachineModel(\n",
      "  (embedding): FeaturesEmbedding(\n",
      "    (embedding): Embedding(309799, 16)\n",
      "  )\n",
      "  (linear): FeaturesLinear(\n",
      "    (fc): Embedding(309799, 1)\n",
      "  )\n",
      "  (fm): FactorizationMachine()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:36,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_loss: 4.774, valid_loss: 2.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:08<00:32,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train_loss: 2.507, valid_loss: 2.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:12<00:28,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train_loss: 2.124, valid_loss: 2.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:16<00:24,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train_loss: 1.893, valid_loss: 2.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:20<00:20,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train_loss: 1.732, valid_loss: 2.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:24<00:16,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train_loss: 1.616, valid_loss: 2.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:28<00:12,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train_loss: 1.530, valid_loss: 2.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:32<00:08,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train_loss: 1.466, valid_loss: 2.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:36<00:04,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train_loss: 1.418, valid_loss: 2.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train_loss: 1.381, valid_loss: 2.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(model, data, logger, setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d619f09-070c-4f57-8262-0a2daa3e779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, setting):\n",
    "    predicts = list()\n",
    "    # if use_best_model == True:\n",
    "    #     model.load_state_dict(torch.load(f'./saved_models/{setting.save_time}_{model}_model.pt'))\n",
    "    # else:\n",
    "    #     pass\n",
    "    model.eval()\n",
    "\n",
    "    for idx, data in enumerate(dataloader['test_dataloader']):\n",
    "        x = data[0].to(device)\n",
    "        y_hat = model(x)\n",
    "        predicts.extend(y_hat.tolist())\n",
    "    return predicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89d66f3c-e4de-4637-a089-25a356061baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- SAVE FactorizationMachineModel(\n",
      "  (embedding): FeaturesEmbedding(\n",
      "    (embedding): Embedding(309818, 16)\n",
      "  )\n",
      "  (linear): FeaturesLinear(\n",
      "    (fc): Embedding(309818, 1)\n",
      "  )\n",
      "  (fm): FactorizationMachine()\n",
      ") PREDICT ---------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './saved_models/20230416_122752_FactorizationMachineModel(\\n  (embedding): FeaturesEmbedding(\\n    (embedding): Embedding(309818, 16)\\n  )\\n  (linear): FeaturesLinear(\\n    (fc): Embedding(309818, 1)\\n  )\\n  (fm): FactorizationMachine()\\n)_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--------------- SAVE \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m PREDICT ---------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m submission \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(data_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39msample_submission.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m submission[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test(model, data, setting)\n\u001b[1;32m      5\u001b[0m submission\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, dataloader, setting)\u001b[0m\n\u001b[1;32m      2\u001b[0m predicts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m use_best_model \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./saved_models/\u001b[39;49m\u001b[39m{\u001b[39;49;00msetting\u001b[39m.\u001b[39;49msave_time\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel\u001b[39m}\u001b[39;49;00m\u001b[39m_model.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      5\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:581\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    579\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 581\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    583\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    585\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './saved_models/20230416_122752_FactorizationMachineModel(\\n  (embedding): FeaturesEmbedding(\\n    (embedding): Embedding(309818, 16)\\n  )\\n  (linear): FeaturesLinear(\\n    (fc): Embedding(309818, 1)\\n  )\\n  (fm): FactorizationMachine()\\n)_model.pt'"
     ]
    }
   ],
   "source": [
    "######################## SAVE PREDICT\n",
    "print(f'--------------- SAVE {model} PREDICT ---------------')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv')\n",
    "submission['rating'] = test(model, data, setting)\n",
    "submission.to_csv('result', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
